{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part a) SGD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from imageio import imread\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import seaborn as sns\n",
    "import os\n",
    "from common import *\n",
    "from models import own_LinRegGD\n",
    "import cv2\n",
    "\n",
    "print(f\"Root directory: {os.getcwd()}\")\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"serif\",\n",
    "    \"font.serif\": [\"Palatino\"],\n",
    "    \"font.size\": 10,\n",
    "})\n",
    "\n",
    "#%matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED_VALUE = 70707070\n",
    "np.random.seed(SEED_VALUE)\n",
    "SAVE_FIGURES = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading data and resizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the terrain\n",
    "terrain1_file = \"SRTM_data_Norway_1.tif\"\n",
    "terrain2_file = \"SRTM_data_Norway_2.tif\"\n",
    "terrain1 =  imread(f'{INPUT_DATA}{terrain1_file}')\n",
    "terrain2 = imread(f'{INPUT_DATA}{terrain2_file}')\n",
    "\n",
    "# Resizing the image\n",
    "rescale_factor = 0.1\n",
    "y_size = int(terrain1.shape[0] * rescale_factor)\n",
    "x_size = int(terrain1.shape[1] * rescale_factor)\n",
    "terrain1Resized = cv2.resize(terrain1, (x_size, y_size))\n",
    "terrain2Resized = cv2.resize(terrain2, (x_size, y_size))\n",
    "\n",
    "# Plotting terrain\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.title.set_text(\"Terrain over Norway 1 (Resized)\")\n",
    "ax1.set_xlabel(\"X\"); ax1.set_ylabel(\"Y\")\n",
    "surf1 = ax1.imshow(terrain1Resized, cmap='gray')\n",
    "ax2.title.set_text(\"Terrain over Norway 2 (Resized)\")\n",
    "ax2.set_xlabel(\"X\"); ax2.set_ylabel(\"Y\")\n",
    "surf2 = ax2.imshow(terrain2Resized, cmap='gray')\n",
    "\n",
    "if SAVE_FIGURES:\n",
    "    plt.savefig(f\"{REPORT_FIGURES}{EX_A}terrain_data_resized.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating image patches and Terrain data selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nXpatches = 3; nYpatches=6\n",
    "y_steps = int(terrain2Resized.shape[0] / nYpatches); print(y_steps)\n",
    "x_steps = int(terrain2Resized.shape[1] / nXpatches); print(x_steps)\n",
    "\n",
    "patches_1 = create_img_patches(terrain1Resized, y_steps, x_steps)\n",
    "if SAVE_FIGURES:\n",
    "    fig1 = plotTerrainPatches(patches_1, nYpatches, nXpatches, plotTitle=\"Terrain1 patches\")\n",
    "    plt.savefig(f\"{REPORT_FIGURES}{EX_A}Terrain1_patches.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "patches_2 = create_img_patches(terrain2Resized, y_steps, x_steps)\n",
    "if SAVE_FIGURES:\n",
    "    fig2 = plotTerrainPatches(patches_2, nYpatches, nXpatches, plotTitle=\"Terrain2 patches\")\n",
    "    plt.savefig(f\"{REPORT_FIGURES}{EX_A}Terrain2_patches.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "# Choosing two interesting terrain patches\n",
    "img1 = patches_1[2]\n",
    "img2 = patches_2[5]\n",
    "x1, y1, z1 = createTerrainData(img1)\n",
    "x2, y2, z2 = createTerrainData(img2)\n",
    "\n",
    "# Constructing the terrain data\n",
    "terrain_data = 1\n",
    "if terrain_data == 1: # Choosing terrain1*\n",
    "    x, y, z = x1, y1, z1.copy() \n",
    "    #z_min = np.min(z)\n",
    "    z_max = np.max(z)\n",
    "    z = z1\n",
    "\n",
    "elif terrain_data == 2: # Choosing terrain2\n",
    "    x, y, z = x2, y2, z2.copy() \n",
    "    #z_min = np.min(z)\n",
    "    z_max = np.max(z)\n",
    "    z = z2\n",
    "    \n",
    "z_flat = z.ravel(); z_flat = z_flat.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_length(t, t0, t1):\n",
    "    return t0/(t+t1)\n",
    "\n",
    "def new_sgd(X_train, t_train, theta, n_epoch, batch_size, eta, lr_scheduler=False, ridge=False, lmb=0):\n",
    "    n_batches = int(X_train.shape[0] // batch_size)\n",
    "    Xt = np.concatenate((X_train, t_train), axis=1)\n",
    "    print(f\"Number of minibatches: {n_batches}\")\n",
    "    \n",
    "    if lr_scheduler:\n",
    "        t0 = 1.0; t1 = 100\n",
    "        eta = t0/t1\n",
    "        print(f\"Using learning rate scheduler with initial learning rate: {eta}\")\n",
    "\n",
    "    \n",
    "    for epoch in tqdm(range(n_epoch), f\"Training {n_epoch} epochs\"):      \n",
    "        batches = np.take(Xt, np.random.permutation(Xt.shape[0]), axis=0)\n",
    "        batches = np.array_split(batches, n_batches, axis=0)\n",
    "        \n",
    "        for batch in batches:\n",
    "            xi = batch[:, :-1]\n",
    "            yi = batch[:, -1].reshape(-1,1)\n",
    "            \n",
    "            gradients = 2.0* xi.T @ ((xi @ theta)-yi)\n",
    "            if ridge:\n",
    "                # TODO: the coff regularization is not implemented correct. \n",
    "                #gradients +=  lmb*np.eye(theta.shape[0])\n",
    "                update = lmb*np.ones(theta.shape[0]).reshape((-1,1))\n",
    "                gradients += update \n",
    "            \n",
    "            theta = theta - eta*gradients\n",
    "\n",
    "            if lr_scheduler:\n",
    "                t = epoch*n_batches+epoch\n",
    "                eta = step_length(t, t0, t1)\n",
    "            \n",
    "    return theta.ravel()\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Momentum SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def momentum_sgd(X_train, t_train, theta, n_epoch, batch_size, eta, beta, lr_scheduler=False, ridge=False, lmb=0):\n",
    "    n_batches = int(X_train.shape[0] // batch_size)\n",
    "    Xt = np.concatenate((X_train, t_train), axis=1)\n",
    "    print(f\"Number of minibatches: {n_batches}\")\n",
    "    \n",
    "    if lr_scheduler:\n",
    "        t0 = 1.0; t1 = 100\n",
    "        eta = t0/t1\n",
    "        print(f\"Using learning rate scheduler with initial learning rate: {eta}\")\n",
    "\n",
    "    \n",
    "    for epoch in tqdm(range(n_epoch), f\"Training {n_epoch} epochs\"):      \n",
    "        batches = np.take(Xt, np.random.permutation(Xt.shape[0]), axis=0)\n",
    "        batches = np.array_split(batches, n_batches, axis=0)\n",
    "        momentum = 0\n",
    "        \n",
    "        for batch in batches:\n",
    "            xi = batch[:, :-1]\n",
    "            yi = batch[:, -1].reshape(-1,1)\n",
    "            \n",
    "            # (2.0/n)*X.T @ (X @ beta-y)\n",
    "            gradients = 2.0* xi.T @ ((xi @ theta)-yi)\n",
    "            \"\"\"\n",
    "            RIDGE NOT YET SUPPORTED\n",
    "            if ridge:\n",
    "                # TODO: the coff regularization is not implemented correct. \n",
    "                #gradients +=  lmb*np.eye(theta.shape[0])\n",
    "                update = lmb*np.ones(theta.shape[0]).reshape((-1,1))\n",
    "                gradients += update \n",
    "            \"\"\"\n",
    "            momentum = beta*momentum + eta*gradients\n",
    "            theta = theta - momentum\n",
    "\n",
    "            if lr_scheduler:\n",
    "                t = epoch*n_batches+epoch\n",
    "                eta = step_length(t, t0, t1)\n",
    "            \n",
    "    return theta.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "# Created test data\n",
    "\"\"\"\"\"\"\n",
    "SEED_VALUE = 70707070\n",
    "np.random.seed(SEED_VALUE)\n",
    "\n",
    "n = 100\n",
    "x = 2*np.random.rand(n,1)\n",
    "t = 4+3*x+np.random.randn(n,1)\n",
    "X = np.c_[np.ones((n,1)), x]\n",
    "X = np.hstack([X, x**2])\n",
    "X = X[:,1:]\n",
    "X_train, X_test, t_train, t_test = train_test_split(X, t, test_size=0.2, shuffle=True)\n",
    "\n",
    "\n",
    "# Terrain data\n",
    "\"\"\"\n",
    "degree = 1\n",
    "X = create_X(x,y, n=degree)\n",
    "X = remove_intercept(X)\n",
    "X_train, X_test, t_train, t_test = train_test_split(X, z_flat, test_size=0.2, shuffle=True)\n",
    "\"\"\"\n",
    "\n",
    "X_train, X_test = standard_scaling(X_train, X_test)\n",
    "t_train, t_test = standard_scaling(t_train, t_test)\n",
    "\n",
    "_,features_X = X_train.shape \n",
    "theta_initial_values = np.random.randn(features_X,1)\n",
    "eta = 0.01\n",
    "lmb=0.0001\n",
    "\n",
    "n_epochs = 1000\n",
    "batch_size = 5  #size of each minibatch\n",
    "lr_scheduler = True\n",
    "\n",
    "theta = new_sgd(X_train, t_train, theta_initial_values, n_epochs, batch_size, eta, lr_scheduler=lr_scheduler, ridge=True, lmb=lmb)\n",
    "\n",
    "print(f\"theta from new SGD: {theta}\")\n",
    "\n",
    "theta = momentum_sgd(X_train, t_train, theta_initial_values, n_epochs, batch_size, eta, beta=0.9, lr_scheduler=lr_scheduler)\n",
    "\n",
    "print(f\"theta from momentum SGD: {theta}\")\n",
    "\n",
    "sgdreg = SGDRegressor(max_iter = n_epochs, fit_intercept=False, penalty='l2', eta0=eta, alpha=lmb)\n",
    "# sgdreg = SGDRegressor(max_iter = n_epochs, fit_intercept=False, penalty=None, eta0=eta)\n",
    "sgdreg.fit(X_train,t_train.ravel())\n",
    "print(f\"sgdreg from scikit: {sgdreg.coef_}\")\n",
    "# print(f\"sgdreg from scikit: {sgdreg.intercept_}, {sgdreg.coef_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
