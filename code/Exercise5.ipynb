{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 5: Lasso Regression on the Franke function  with resampling (Score 10 points))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from common import *\n",
    "import pandas as pd\n",
    "#from mpl_toolkits.mplot3d Axes3D\n",
    "import sklearn.linear_model as lm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from warnings import simplefilter\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "simplefilter(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "print(f\"Root directory: {os.getcwd()}\")\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"serif\",\n",
    "    \"font.serif\": [\"Palatino\"],\n",
    "    \"font.size\": 10,\n",
    "})\n",
    "\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.5\n",
    "Start off by defining the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 6853\n",
    "np.random.seed(SEED)\n",
    "maxdegree = 12\n",
    "n = 20\n",
    "x = np.sort(np.random.uniform(0, 1, n))\n",
    "y = np.sort(np.random.uniform(0, 1, n))\n",
    "x,y = np.meshgrid(x,y)\n",
    "t = FrankeFunction(x, y) + noise_factor(n, factor=0.2)\n",
    "min_lambda = -7\n",
    "max_lambda = 2\n",
    "nlambdas = 100\n",
    "lambdas = np.logspace(min_lambda, max_lambda, nlambdas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to essentially repeat the previous two exercises, as such, this exercise will follow in the footsteps of exercise 4. The difference is that the sci-kit learn implementation of Lasso regression is used. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a searchlandscape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mse = np.zeros((maxdegree, nlambdas))\n",
    "train_mse = np.zeros_like(test_mse)\n",
    "model_list = np.empty_like(test_mse, dtype=object)\n",
    "optimal_deg = 0\n",
    "optimal_lmb = 0\n",
    "lambda_degree = 0\n",
    "best_mse = np.inf\n",
    "\n",
    "for deg in range(1, maxdegree+1):\n",
    "    for lmb in range(len(lambdas)):\n",
    "\n",
    "        X = create_X(x,y,n=deg)\n",
    "\n",
    "        X_train, X_test, z_train, z_test = prepare_data(X, t.ravel(), SEED, scale_X=True, skip_intercept=True)\n",
    "\n",
    "        model = lm.Lasso(lambdas[lmb], fit_intercept=False, random_state=SEED)\n",
    "        model.fit(X_train, z_train)\n",
    "        z_hat_train = model.predict(X_train)\n",
    "        z_hat_test = model.predict(X_test)\n",
    "\n",
    "        test_mse[deg-1,lmb] = MSE(z_test, z_hat_test)\n",
    "        train_mse[deg-1, lmb] = MSE(z_train, z_hat_train)\n",
    "        model_list[deg-1,lmb] = model\n",
    "        \n",
    "        if test_mse[deg-1,lmb] < best_mse:\n",
    "            best_mse = test_mse[deg-1, lmb]\n",
    "            optimal_deg = deg\n",
    "            optimal_lmb = lambdas[lmb]\n",
    "            lambda_degree = lmb\n",
    "\n",
    "print(best_mse)\n",
    "print(f\"{optimal_lmb:g}\")\n",
    "print(optimal_deg)\n",
    "print(train_mse[deg-1, lmb])\n",
    "optimal_model = model_list[deg-1, lambda_degree]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as mticker\n",
    "%matplotlib\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.title.set_text(\"Plot of the Search Landscape\")\n",
    "ax.set_xlabel(\"Polynomial degree\"); ax.set_ylabel(\"Lambda index\"); ax.set_zlabel(\"MSE\")\n",
    "#ax.set_yticklabels(f\"{np.log10(lambdas[i])}\" for i in np.linspace(0,499,6,dtype=int))\n",
    "ax.set_xticklabels(f\"{deg-2}\" for deg in range(1, maxdegree+2,2))\n",
    "\n",
    "degs, lambs = np.meshgrid(range(maxdegree), range(nlambdas))\n",
    "print(degs.shape)\n",
    "print(lambs.shape)\n",
    "print(test_mse.shape)\n",
    "ax.scatter(optimal_deg - 1, lambda_degree, best_mse, c='r', marker='o', s=100)\n",
    "\n",
    "surf = ax.plot_surface(degs, lambs, test_mse.swapaxes(0,1), cmap=cm.coolwarm)\n",
    "ax.view_init(elev=14., azim=-58.)\n",
    "# plt.savefig(f\"{REPORT_FIGURES}{EX5}search_landscape_lasso.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bootstrap with Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "np.random.seed(SEED)\n",
    "maxdegree = 18\n",
    "n_points = [20, 40]\n",
    "x = np.sort(np.random.uniform(0, 1, n))\n",
    "y = np.sort(np.random.uniform(0, 1, n))\n",
    "x,y = np.meshgrid(x,y)\n",
    "z = FrankeFunction(x,y) + noise_factor(n, factor=0.2)\n",
    "\n",
    "min_lambda = -7\n",
    "max_lambda = 2\n",
    "nlambdas=100\n",
    "lambdas = np.logspace(min_lambda,max_lambda, nlambdas)\n",
    "#lambdas = [np.log10(min_lambda), optimal_lmb, np.log10(max_lambda)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in n_points:\n",
    "    for i in [0, lambda_degree, len(lambdas)-1]:\n",
    "        n_bootstraps = int(0.5*n)\n",
    "        lmb = lambdas[i]\n",
    "        polydegree = np.arange(1, maxdegree+1)\n",
    "        MSE_test, MSE_train, bias, variance = bootstrap(x, y, z, maxdegree, n_bootstraps, lm.Lasso(lmb, fit_intercept=False, random_state=SEED), SEED, is_scikit=True)\n",
    "\n",
    "        plt.plot(polydegree, MSE_test,\"m\", label='MSE test')\n",
    "        #plt.plot(polydegree, MSE_train,\"c\", label='MSE train')\n",
    "        plt.plot(polydegree, bias,\"b--\", label='bias')\n",
    "        plt.plot(polydegree, variance,\"r--\", label='Variance')\n",
    "        #plt.plot(polydegree, bias+variance,\"g--\", label='bias+variance')\n",
    "\n",
    "        plt.title(fr\"Bias-Variance tradeoff for {n*n} datapoints using {n_bootstraps} bootstraps with $\\lambda$: {lmb:.0e}\")\n",
    "        plt.xlabel(\"Model complexity / Polynomial Degree\")\n",
    "        plt.ylabel(\"Prediction Error - MSE\")\n",
    "        plt.xticks(polydegree)\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        # plt.savefig(f\"{REPORT_FIGURES}{EX5}lasso_complexity_using_bootstrap_function_lmb{n}{i}.pdf\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(SEED)\n",
    "maxdegree = 12\n",
    "n = 20\n",
    "x = np.sort(np.random.uniform(0, 1, n))\n",
    "y = np.sort(np.random.uniform(0, 1, n))\n",
    "x,y = np.meshgrid(x,y)\n",
    "z = FrankeFunction(x,y) + noise_factor(n, factor=0.2)\n",
    "\n",
    "min_lambda = -7\n",
    "max_lambda = 2\n",
    "nlambdas = 3\n",
    "lambdas = np.logspace(min_lambda,max_lambda, nlambdas+1)\n",
    "\n",
    "for i in range(nlambdas+1):\n",
    "    lmb = lambdas[i]\n",
    "\n",
    "    boot_strp_MSE_test, _, _, boot_strp_variance = bootstrap(x, y, z, maxdegree, int(0.5*n), lm.Lasso(lmb, fit_intercept=False, random_state=SEED), SEED, is_scikit=True)\n",
    "    boot_strp_std = np.sqrt(boot_strp_variance)\n",
    "\n",
    "    for degree in range(3,maxdegree):\n",
    "        X = create_X(x,y,degree)\n",
    "        X = remove_intercept(X)\n",
    "        \n",
    "        mean_folds_error = np.zeros(6)\n",
    "        mse_std_arr = np.zeros(6)\n",
    "        for folds in range(5,11):\n",
    "            \n",
    "            implemented_scores = cross_val(k = folds, model = \"Lasso\", X = X, z = z, degree=degree,lmb=lmb, shuffle=True, random_state = SEED, scale_t=False)\n",
    "            mean_folds_error[folds-5] = np.mean(implemented_scores)\n",
    "            mse_std_arr[folds-5] = np.std(implemented_scores)\n",
    "\n",
    "        plt.plot(np.arange(5,11), np.ones(6)*boot_strp_MSE_test[degree],\"--\", label =\"Mean MSE bootstrap with STD\")\n",
    "        #plt.fill_between(np.arange(5,11), np.ones(6)*boot_strp_MSE_test[degree]-boot_strp_std[degree],\n",
    "                        #np.ones(6)*boot_strp_MSE_test[degree]+boot_strp_std[degree], alpha = 0.2 )\n",
    "        plt.plot(np.arange(5,11), mean_folds_error, \"o--\",  label = \"Mean MSE CV\")\n",
    "        plt.fill_between(np.arange(5,11), mean_folds_error-mse_std_arr, mean_folds_error+mse_std_arr,  alpha = 0.2, color = \"darkorange\")\n",
    "        plt.title(fr\"Model complexity: {degree} degrees, $\\lambda$ = {lmb:.2e}\")\n",
    "        plt.xlabel(\"K-fold\")\n",
    "        plt.ylabel(\"MSE\")\n",
    "        #plt.ylim(0,2)\n",
    "        plt.xticks(np.arange(5,11))\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        # plt.savefig(f\"{REPORT_FIGURES}{EX5}lasso_mse_cv_boot{i}{degree}.pdf\")\n",
    "\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "20551ddceb59dc51fa628b42bb2a7289171df926f90359af355cededb82457a3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('in5520': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
