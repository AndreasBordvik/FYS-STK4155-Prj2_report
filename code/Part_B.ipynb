{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from imageio import imread\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import seaborn as sns\n",
    "import os\n",
    "import cv2\n",
    "from common import *\n",
    "from models import *\n",
    "import tensorflow as tf\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(tf. __version__) \n",
    "# print('tensorflow version', tf.__version__)\n",
    "# print(tf.config.list_physical_devices('GPU'))\n",
    "# print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "print(f\"Root directory: {os.getcwd()}\")\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"serif\",\n",
    "    \"font.serif\": [\"Palatino\"],\n",
    "    \"font.size\": 10,\n",
    "})\n",
    "\n",
    "#%matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED_VALUE = 70707070\n",
    "np.random.seed(SEED_VALUE)\n",
    "SAVE_FIGURES = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading data and resizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the terrain\n",
    "terrain1_file = \"SRTM_data_Norway_1.tif\"\n",
    "terrain2_file = \"SRTM_data_Norway_2.tif\"\n",
    "terrain1 =  imread(f'{INPUT_DATA}{terrain1_file}')\n",
    "terrain2 = imread(f'{INPUT_DATA}{terrain2_file}')\n",
    "\n",
    "# Resizing the image\n",
    "rescale_factor = 0.1\n",
    "y_size = int(terrain1.shape[0] * rescale_factor)\n",
    "x_size = int(terrain1.shape[1] * rescale_factor)\n",
    "terrain1Resized = cv2.resize(terrain1, (x_size, y_size))\n",
    "terrain2Resized = cv2.resize(terrain2, (x_size, y_size))\n",
    "\n",
    "# Plotting terrain\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.title.set_text(\"Terrain over Norway 1 (Resized)\")\n",
    "ax1.set_xlabel(\"X\"); ax1.set_ylabel(\"Y\")\n",
    "surf1 = ax1.imshow(terrain1Resized, cmap='gray')\n",
    "ax2.title.set_text(\"Terrain over Norway 2 (Resized)\")\n",
    "ax2.set_xlabel(\"X\"); ax2.set_ylabel(\"Y\")\n",
    "surf2 = ax2.imshow(terrain2Resized, cmap='gray')\n",
    "\n",
    "if SAVE_FIGURES:\n",
    "    plt.savefig(f\"{REPORT_FIGURES}{EX_A}terrain_data_resized.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating image patches and Terrain data selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nXpatches = 3; nYpatches=6\n",
    "y_steps = int(terrain2Resized.shape[0] / nYpatches); print(y_steps)\n",
    "x_steps = int(terrain2Resized.shape[1] / nXpatches); print(x_steps)\n",
    "\n",
    "patches_1 = create_img_patches(terrain1Resized, y_steps, x_steps)\n",
    "if SAVE_FIGURES:\n",
    "    fig1 = plotTerrainPatches(patches_1, nYpatches, nXpatches, plotTitle=\"Terrain1 patches\")\n",
    "    plt.savefig(f\"{REPORT_FIGURES}{EX_A}Terrain1_patches.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "patches_2 = create_img_patches(terrain2Resized, y_steps, x_steps)\n",
    "if SAVE_FIGURES:\n",
    "    fig2 = plotTerrainPatches(patches_2, nYpatches, nXpatches, plotTitle=\"Terrain2 patches\")\n",
    "    plt.savefig(f\"{REPORT_FIGURES}{EX_A}Terrain2_patches.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "# Choosing two interesting terrain patches\n",
    "img1 = patches_1[2]\n",
    "img2 = patches_2[5]\n",
    "x1, y1, z1 = createTerrainData(img1)\n",
    "x2, y2, z2 = createTerrainData(img2)\n",
    "\n",
    "# Constructing the terrain data\n",
    "terrain_data = 1\n",
    "if terrain_data == 1: # Choosing terrain1*\n",
    "    x, y, z = x1, y1, z1.copy() \n",
    "    #z_min = np.min(z)\n",
    "    z_max = np.max(z)\n",
    "    z = z1\n",
    "\n",
    "elif terrain_data == 2: # Choosing terrain2\n",
    "    x, y, z = x2, y2, z2.copy() \n",
    "    #z_min = np.min(z)\n",
    "    z_max = np.max(z)\n",
    "    z = z2\n",
    "    \n",
    "z_flat = z.ravel(); z_flat = z_flat.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real Terrain data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(4155)\n",
    "\n",
    "degree = 1\n",
    "X = create_X(x,y, degree)\n",
    "X = X[:,1:]\n",
    "\n",
    "X_train, X_test, t_train, t_test = train_test_split(X, z_flat, test_size=0.2, shuffle=True)\n",
    "\n",
    "X_train, X_test = standard_scaling(X_train, X_test)\n",
    "t_train, t_test = standard_scaling(t_train, t_test)\n",
    "\n",
    "lr_upper_limit = learning_rate_upper_limit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing own NN implementation against sklearn and tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "epochs = 100\n",
    "batch_size = 100\n",
    "eta = 0.001\n",
    "nbf_features = X_train.shape[1]\n",
    "use_l2 = True\n",
    "lmb = 0.00001\n",
    "hidden_size = 25\n",
    "act_func = \"sigmoid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "own_model, sk_model, tf_model = NN_regression_comparison(eta, nbf_features, \n",
    "                                                         batch_size, epochs, \n",
    "                                                         X_test=X_test.copy(), \n",
    "                                                         t_test=t_test.copy(),\n",
    "                                                         lmb=lmb, hidden_size=hidden_size, \n",
    "                                                         act_func=act_func,\n",
    "                                                         )\n",
    "# Own model\n",
    "_, _ = own_model.fit(X_train.copy(), t_train.copy(), batch_size=batch_size, epochs=epochs, verbose=False)\n",
    "t_hat_test_own = own_model.predict(X_test.copy())\n",
    "print(\"MSE using own implemented NN:\",MSE(t_test, t_hat_test_own),\"\\n\")\n",
    "\n",
    "# SK learn\n",
    "sk_model.fit(X_train.copy(), t_train.copy().ravel())\n",
    "t_hat_test_sk_model = sk_model.predict(X_test.copy())\n",
    "print(\"MSE using SK learn NN:\", MSE(t_test, t_hat_test_sk_model),\"\\n\")\n",
    "\n",
    "# Tensorflow \n",
    "tf_model.fit(X_train.copy(), t_train.copy(), epochs=epochs,  batch_size=batch_size, verbose=0)\n",
    "t_hat_test_tf = tf_model.predict(X_test.copy())\n",
    "print(\"MSE using tensorflow NN:\",MSE(t_test, t_hat_test_tf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid search using simple architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "batch_size = 300\n",
    "nbf_features = X_train.shape[1]\n",
    "apply_lr_scheduler = False\n",
    "hidden_sizes = np.array([40,30,20,10])\n",
    "eta_list = np.concatenate([np.array([0.3]), np.logspace(-1, -4, 9)], axis=0)\n",
    "lmb_list = np.concatenate([np.zeros(1).astype(float), np.logspace(-5, -1, 9)], axis=0)\n",
    "act_func = \"sigmoid\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search small architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_mtrx_MSE = np.zeros(shape=(hidden_sizes.shape[0], eta_list.shape[0], lmb_list.shape[0]))\n",
    "heatmap_mtrx_MSE_tf = np.zeros_like(heatmap_mtrx_MSE)\n",
    "\n",
    "parameters_best_MSE = {\"best_MSE\" : np.Inf, \"R2_at_best_MSE\" : np.Inf ,\"parameters\":0, \"neurons_first_hidden\":0, \"learning_rate\":0, \"lambda\":0}\n",
    "parameters_best_MSE_tf = {\"best_MSE\" : np.Inf, \"R2_at_best_MSE\" : np.Inf , \"parameters\":0, \"neurons_first_hidden\":0, \"learning_rate\":0, \"lambda\":0}\n",
    "best_models = {\"own_NN\":None, \"tf_NN\":None}\n",
    "\n",
    "results_simple_df = pd.DataFrame(columns=[\"MSE_tensorflow\",\"R2_tensorflow\",\"MSE_own_NN\",\"R2_own_NN\",\n",
    "                                          \"parameters_own_NN\",\"neurons_first_hidden\",\"learning_rate\",\n",
    "                                          \"regularization\"])\n",
    "# Grid search on eta and lambda \n",
    "i = 0\n",
    "for n, hidden_size in tqdm(enumerate(hidden_sizes)):\n",
    "    for y, lmb in enumerate(lmb_list):\n",
    "        for x, eta in enumerate(eta_list):\n",
    "            np.random.seed(4155)\n",
    "            own_model, tf_model = NN_simple_architecture(eta, nbf_features,\n",
    "                                                         problem_type=\"regression\",\n",
    "                                                         X_test=X_test.copy(), t_test=t_test.copy(),\n",
    "                                                         lmb=lmb, \n",
    "                                                         hidden_size=hidden_size, \n",
    "                                                         act_func=act_func)\n",
    "            \n",
    "            print(f\"Neurons in first hidden: {hidden_size} - Parameters: {own_model.nbf_parameters} - Lambda: {lmb} -Eta: {eta}\")\n",
    "            # Own model\n",
    "            train_losses, test_losses = own_model.fit(X_train.copy(), t_train.copy(), \n",
    "                                                            batch_size=batch_size, epochs=epochs,\n",
    "                                                            lr_scheduler=apply_lr_scheduler, verbose=False)\n",
    "            t_hat_test_own = own_model.predict(X_test.copy())\n",
    "            \n",
    "            MSE_val = np.around(MSE(t_test, t_hat_test_own), decimals=4)\n",
    "            R2_val = np.around(R2(t_test, t_hat_test_own), decimals=4)\n",
    "            heatmap_mtrx_MSE[n,y,x] = MSE_val\n",
    "\n",
    "            if parameters_best_MSE[\"best_MSE\"] > MSE_val:\n",
    "                print(f\"**New best MSE own NN**: {MSE_val}\")\n",
    "                best_models[\"own_NN\"] = own_model\n",
    "                parameters_best_MSE[\"best_MSE\"] = MSE_val\n",
    "                parameters_best_MSE[\"R2_at_best_MSE\"] = R2_val\n",
    "                parameters_best_MSE[\"parameters\"] = own_model.nbf_parameters\n",
    "                parameters_best_MSE[\"neurons_first_hidden\"] = hidden_size\n",
    "                parameters_best_MSE[\"learning_rate\"] = eta\n",
    "                parameters_best_MSE[\"lambda\"] = lmb\n",
    "                df = pd.DataFrame().from_dict(parameters_best_MSE, orient='index')\n",
    "                df.to_csv(f\"{REPORT_DATA}{EX_B}own_NN_best_training_small_{act_func}.csv\")\n",
    "                \n",
    "                plt.figure()\n",
    "                plt.plot(np.arange(epochs), train_losses, label=\"Train loss\")\n",
    "                plt.plot(np.arange(epochs), test_losses, label=\"Test loss\")\n",
    "                plt.title(f\"Best model own NN\\nMSE: {MSE_val}\\nNumber of parameters: {own_model.nbf_parameters}\\nLearning rate: {eta}\\nL2 Regularization: {lmb}\\n{act_func}\")\n",
    "                plt.xlabel(\"Epochs\")\n",
    "                plt.ylabel(\"Loss\")\n",
    "                plt.legend()\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(f\"{REPORT_FIGURES}{EX_B}own_NN_best_training_small_{act_func}_lr_{eta}.pdf\")\n",
    "            \n",
    "                        \n",
    "            # Tensorflow\n",
    "            tf_model.fit(X_train.copy(), t_train.copy(), batch_size=batch_size, epochs=epochs, verbose=0)\n",
    "            t_hat_test_tf = tf_model.predict(X_test.copy())\n",
    "            \n",
    "            MSE_val_tf = np.around(MSE(t_test, t_hat_test_tf), decimals=4)\n",
    "            heatmap_mtrx_MSE_tf[n, y,x] = MSE_val_tf\n",
    "\n",
    "            if parameters_best_MSE_tf[\"best_MSE\"] > MSE_val_tf:\n",
    "                print(f\"New best MSE tensorflow: {MSE_val_tf}\")\n",
    "                parameters_best_MSE_tf[\"best_MSE\"] = MSE_val_tf\n",
    "                parameters_best_MSE_tf[\"parameters\"] = own_model.nbf_parameters\n",
    "                parameters_best_MSE_tf[\"neurons_first_hidden\"] = hidden_size\n",
    "                parameters_best_MSE_tf[\"learning_rate\"] = eta\n",
    "                parameters_best_MSE_tf[\"lambda\"] = lmb\n",
    "                best_models[\"tf_NN\"] = tf_model\n",
    "            \n",
    "            R2_val_tf = np.around(R2(t_test, t_hat_test_tf), decimals=4)\n",
    "            \n",
    "            \n",
    "            results_simple_df.loc[i] = [MSE_val_tf, R2_val_tf, MSE_val, R2_val, \n",
    "                                        own_model.nbf_parameters, hidden_size, eta, lmb]\n",
    "            results_simple_df.to_csv(f\"{REPORT_DATA}{EX_B}results_small_{act_func}.csv\")\n",
    "            i+=1\n",
    "            \n",
    "    plot_save_NN_results(parameters=own_model.nbf_parameters, model_size=\"small\", eta_list=eta_list, lmb_list=lmb_list, \n",
    "                         heatmap_mtrx=heatmap_mtrx_MSE[n, :,:], heatmap_mtrx_tf=heatmap_mtrx_MSE_tf[n, :,:],\n",
    "                         path=f\"{REPORT_FIGURES}{EX_B}\", activation_type=act_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid search using large architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "Using same parameters as the small architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_mtrx_MSE = np.zeros(shape=(hidden_sizes.shape[0], eta_list.shape[0], lmb_list.shape[0]))\n",
    "heatmap_mtrx_MSE_tf = np.zeros_like(heatmap_mtrx_MSE)\n",
    "\n",
    "parameters_best_MSE = {\"best_MSE\" : np.Inf, \"R2_at_best_MSE\" : np.Inf ,\"parameters\":0, \"neurons_first_hidden\":0, \"learning_rate\":0, \"lambda\":0}\n",
    "parameters_best_MSE_tf = {\"best_MSE\" : np.Inf, \"R2_at_best_MSE\" : np.Inf , \"parameters\":0, \"neurons_first_hidden\":0, \"learning_rate\":0, \"lambda\":0}\n",
    "best_models = {\"own_NN\":None, \"tf_NN\":None}\n",
    "\n",
    "results_large_df = pd.DataFrame(columns=[\"MSE_tensorflow\",\"R2_tensorflow\",\"MSE_own_NN\",\"R2_own_NN\",\n",
    "                                          \"parameters_own_NN\",\"neurons_first_hidden\",\"learning_rate\",\n",
    "                                          \"regularization\"])\n",
    "# Grid search on eta and lambda \n",
    "i = 0\n",
    "for n, hidden_size in tqdm(enumerate(hidden_sizes)):\n",
    "    for y, lmb in enumerate(lmb_list):\n",
    "        for x, eta in enumerate(eta_list):\n",
    "            np.random.seed(4155)\n",
    "            own_model, tf_model = NN_large_architecture(eta, nbf_features,\n",
    "                                                         problem_type=\"regression\",\n",
    "                                                         X_test=X_test.copy(), t_test=t_test.copy(),\n",
    "                                                         lmb=lmb, \n",
    "                                                         hidden_size=hidden_size, \n",
    "                                                         act_func=act_func)\n",
    "            \n",
    "            print(f\"Neurons in first hidden: {hidden_size} - Parameters: {own_model.nbf_parameters} - Lambda: {lmb} -Eta: {eta}\")\n",
    "            # Own model\n",
    "            train_losses, test_losses = own_model.fit(X_train.copy(), t_train.copy(), \n",
    "                                                            batch_size=batch_size, epochs=epochs,\n",
    "                                                            lr_scheduler=apply_lr_scheduler, verbose=False)\n",
    "            t_hat_test_own = own_model.predict(X_test.copy())\n",
    "            \n",
    "            MSE_val = np.around(MSE(t_test, t_hat_test_own), decimals=4)\n",
    "            R2_val = np.around(R2(t_test, t_hat_test_own), decimals=4)\n",
    "            heatmap_mtrx_MSE[n,y,x] = MSE_val\n",
    "\n",
    "            if parameters_best_MSE[\"best_MSE\"] > MSE_val:\n",
    "                print(f\"**New best MSE own NN**: {MSE_val}\")\n",
    "                best_models[\"own_NN\"] = own_model\n",
    "                parameters_best_MSE[\"best_MSE\"] = MSE_val\n",
    "                parameters_best_MSE[\"R2_at_best_MSE\"] = R2_val\n",
    "                parameters_best_MSE[\"parameters\"] = own_model.nbf_parameters\n",
    "                parameters_best_MSE[\"neurons_first_hidden\"] = hidden_size\n",
    "                parameters_best_MSE[\"learning_rate\"] = eta\n",
    "                parameters_best_MSE[\"lambda\"] = lmb\n",
    "                df = pd.DataFrame().from_dict(parameters_best_MSE, orient='index')\n",
    "                df.to_csv(f\"{REPORT_DATA}{EX_B}own_NN_best_training_large_{act_func}.csv\")\n",
    "                \n",
    "                plt.figure()\n",
    "                plt.plot(np.arange(epochs), train_losses, label=\"Train loss\")\n",
    "                plt.plot(np.arange(epochs), test_losses, label=\"Test loss\")\n",
    "                plt.title(f\"Best model own NN\\nMSE: {MSE_val}\\nNumber of parameters: {own_model.nbf_parameters}\\nLearning rate: {eta}\\nL2 Regularization: {lmb}\\n{act_func}\")\n",
    "                plt.xlabel(\"Epochs\")\n",
    "                plt.ylabel(\"Loss\")\n",
    "                plt.legend()\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(f\"{REPORT_FIGURES}{EX_B}own_NN_best_training_large_{act_func}_lr_{eta}.pdf\")\n",
    "            \n",
    "                        \n",
    "            # Tensorflow\n",
    "            tf_model.fit(X_train.copy(), t_train.copy(), batch_size=batch_size, epochs=epochs, verbose=0)\n",
    "            t_hat_test_tf = tf_model.predict(X_test.copy())\n",
    "            \n",
    "            MSE_val_tf = np.around(MSE(t_test, t_hat_test_tf), decimals=4)\n",
    "            heatmap_mtrx_MSE_tf[n, y,x] = MSE_val_tf\n",
    "\n",
    "            if parameters_best_MSE_tf[\"best_MSE\"] > MSE_val_tf:\n",
    "                print(f\"New best MSE tensorflow: {MSE_val_tf}\")\n",
    "                parameters_best_MSE_tf[\"best_MSE\"] = MSE_val_tf\n",
    "                parameters_best_MSE_tf[\"parameters\"] = own_model.nbf_parameters\n",
    "                parameters_best_MSE_tf[\"neurons_first_hidden\"] = hidden_size\n",
    "                parameters_best_MSE_tf[\"learning_rate\"] = eta\n",
    "                parameters_best_MSE_tf[\"lambda\"] = lmb\n",
    "                best_models[\"tf_NN\"] = tf_model\n",
    "            \n",
    "            R2_val_tf = np.around(R2(t_test, t_hat_test_tf), decimals=4)\n",
    "            \n",
    "            \n",
    "            results_large_df.loc[i] = [MSE_val_tf, R2_val_tf, MSE_val, R2_val, \n",
    "                                        own_model.nbf_parameters, hidden_size, eta, lmb]\n",
    "            results_large_df.to_csv(f\"{REPORT_DATA}{EX_B}results_large_{act_func}.csv\")\n",
    "            i+=1\n",
    "            \n",
    "    plot_save_NN_results(parameters=own_model.nbf_parameters, model_size=\"large\", eta_list=eta_list, lmb_list=lmb_list, \n",
    "                         heatmap_mtrx=heatmap_mtrx_MSE[n, :,:], heatmap_mtrx_tf=heatmap_mtrx_MSE_tf[n, :,:],\n",
    "                         path=f\"{REPORT_FIGURES}{EX_B}\", activation_type=act_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XOR classification test\n",
    "The following code checks that a Fixed neural net is able to correctly classify the XOR problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"np.random.seed(4155)\n",
    "X = np.array([[1, 0],\n",
    "              [0, 1],\n",
    "              [1, 1],\n",
    "              [0, 0]])\n",
    "\n",
    "hidden1 = Fixed_layer(nbf_inputs=2, nbf_outputs=2, weights=np.array([[1,1],[1,1]]), bias=np.array([-1.5, -0.5]), activation_function=binary_classifier)\n",
    "output = Fixed_layer(nbf_inputs=2, nbf_outputs=1, weights=np.array([-1,1]), bias=np.array([-0.5]), activation_function=binary_classifier)\n",
    "\n",
    "model = NeuralNetwork()\n",
    "model.add(hidden1)\n",
    "model.add(output)\n",
    "\n",
    "y_hat = model.predict(X)\n",
    "print(f\"y_hat: {y_hat}\")\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Net on XOR problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.random.seed(4155)\n",
    "X_train = np.array([[1., 0.],\n",
    "              [1., 1.],\n",
    "              \n",
    "              [0., 1.]])\n",
    "\n",
    "X_test = np.array([[0., 0.]]) \n",
    "\n",
    "t = np.array([[1.,0.,1.]]).reshape(-1,1)\n",
    "\n",
    "#hidden1 = Layer(nbf_inputs=2, nbf_outputs=4, activation_function=relu)\n",
    "#hidden2 = Layer(nbf_inputs=hidden1.output, nbf_outputs=16)\n",
    "hidden1 = Layer(nbf_inputs=2, nbf_outputs=2, activation=relu, name=\"hidden1\")\n",
    "output = Layer(nbf_inputs=hidden1.output, nbf_outputs=1, name=\"output\")\n",
    "\n",
    "model2 = NeuralNetwork()\n",
    "model2.add(hidden1)\n",
    "model2.add(output)\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 2\n",
    "model2.train_model(X_train, t, batch_size=batch_size, epochs=epochs)\n",
    "y_hat = model2.predict(X_test)\n",
    "print(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "clf = MLPRegressor(hidden_layer_sizes=(2,), max_iter=100, solver=\"sgd\",learning_rate_init=0.001, activation=\"relu\")\n",
    "for i in range(10):\n",
    "    clf.fit(X, t.flatten())\n",
    "print(clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "epochs = 100\n",
    "batch_size = 2\n",
    "eta = 0.001\n",
    "\n",
    "# Creating the model\n",
    "tf_model = tf.keras.Sequential()\n",
    "tf_model.add(tf.keras.layers.Input(shape=(2,)))\n",
    "tf_model.add(tf.keras.layers.Dense(2, activation='relu'))\n",
    "tf_model.add(tf.keras.layers.Dense(1))\n",
    "tf_model.compile(loss='mse', optimizer=tf.optimizers.SGD(learning_rate=eta))\n",
    "\n",
    "\n",
    "# Model training\n",
    "tf_model.fit(X_train, t, epochs=epochs,  batch_size=batch_size, verbose=1)\n",
    "\n",
    "# Model predictions\n",
    "y_hat = tf_model.predict(X_test)\n",
    "print(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(4155)\n",
    "X_train = np.array([[1., 0.]])\n",
    "t_train = np.array([[1.]]).reshape(-1,1)\n",
    "\n",
    "\n",
    "hidden1 = Fixed_layer(nbf_inputs=2, nbf_outputs=2, weights=np.array([[1.,0.],[1.,0.]]), bias=np.array([0.01, 0.01]), activation=\"sigmoid\")\n",
    "output = Fixed_layer(nbf_inputs=2, nbf_outputs=1, weights=np.array([[1.],[0.]]), bias=np.array([0.01]), activation=\"sigmoid\")\n",
    "\n",
    "model = NeuralNetwork(learning_rate=1.0)\n",
    "model.add(hidden1)\n",
    "model.add(output)\n",
    "\n",
    "\n",
    "pred = model.predict(X_train)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.sequential_layers[0].z)\n",
    "print(model.sequential_layers[0].a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.sequential_layers[-1].z)\n",
    "print(model.sequential_layers[-1].a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X_train.shape:\",X_train.shape)\n",
    "print(\"t_train.shape:\",t_train.shape)\n",
    "model.train_model(X_train, t_train, epochs=1, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sigmoid(1+0.01) + 0.01)\n",
    "print(sigmoid(sigmoid(1+0.01) + 0.01))\n",
    "print(sigmoid(1+0.01) + 0.01)\n",
    "\n",
    "\n",
    "print(sigmoid(1+0.01)*(1-sigmoid(1+0.01)))\n",
    "\n",
    "print(0.3323*0.1957)\n",
    "\n",
    "print(-(sigmoid(+0.01) * 0.3323 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(9)\n",
    "print(a)\n",
    "\n",
    "b = a <= 3\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbf_inputs = 10\n",
    "nbf_neurons = 3\n",
    "weights = np.random.randn(nbf_inputs, nbf_neurons)\n",
    "nbf_weights = weights.size\n",
    "print(nbf_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "print(np.concatenate([np.array([0.5]), np.logspace(-1, -4, 10)], axis=0))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "664767e83c7b06364e16bf4bb7694b1f8b5947c6e3e0843db3deeed47f8be06a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('fysstk1': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
