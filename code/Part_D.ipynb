{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification with Neural Newtork:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from common import *\n",
    "from models import LogReg, NeuralNetwork, Layer, TorchNeuralNetwork\n",
    "import seaborn as sns\n",
    "from matplotlib.pyplot import figure\n",
    "import numpy as np \n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from matplotlib import cm\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(tf. __version__) \n",
    "# print('tensorflow version', tf.__version__)\n",
    "# print(tf.config.list_physical_devices('GPU'))\n",
    "# print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "print(f\"Root directory: {os.getcwd()}\")\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"serif\",\n",
    "    \"font.serif\": [\"Palatino\"],\n",
    "    \"font.size\": 10,\n",
    "})\n",
    "\n",
    "#%matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def model_metrics(X_test, y_test, model):\n",
    "    \n",
    "    y_hat = model.predict(X_test)\n",
    "    prediction_val = [1 if x > 0.5 else 0 for x in y_hat.data.numpy()]\n",
    "    correct_val = (prediction_val == y_test.numpy()).sum()\n",
    "    if type(y_hat) == torch.Tensor:\n",
    "        y_test = y_test.detach().numpy()\n",
    "        conf_mat = confusion_matrix(y_test, prediction_val)\n",
    "    else:\n",
    "         conf_mat = confusion_matrix(y_test, prediction_val)\n",
    "    \n",
    "    print(f\"Accuracy: {correct_val/len(y_test)}\")\n",
    "        \n",
    "    return conf_mat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data_utils\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data,cancer.target,test_size=0.30,random_state=4155)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "input_dim = X_train.shape[1]\n",
    "print(input_dim)\n",
    "\n",
    "\n",
    "X_test_scaled_torch = torch.from_numpy(X_test_scaled).float()\n",
    "y_test_torch = torch.from_numpy(y_test).float()\n",
    "\n",
    "#prepare dataset for torch dataloader:\n",
    "trainset = data_utils.TensorDataset(torch.from_numpy(X_train_scaled).float(),\n",
    "                                 torch.from_numpy(y_train).float())\n",
    "\n",
    "#create torch dataloader: \n",
    "trainloader = data_utils.DataLoader(trainset, batch_size=4, shuffle=True)\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 10\n",
    "nbf_features = X_train.shape[1]\n",
    "apply_lr_scheduler = False\n",
    "hidden_sizes = np.array([32,16,8])\n",
    "eta_list = np.logspace(-1, -4, 6)\n",
    "lmb_list = np.logspace(-5, 0, 6)\n",
    "act_func = \"sigmoid\"\n",
    "print(f\"len of testset: {len(y_test)}\")\n",
    "\n",
    "# Grid search on eta and lambda \n",
    "best_acc_homebrew = 0\n",
    "worst_acc_homebrew = 100\n",
    "best_model_homebrew = \"\"\n",
    "worst_model_homebrew = \"\"\n",
    "\n",
    "best_acc_torch = 0\n",
    "worst_acc_torch = 100\n",
    "best_model_torch = \"\"\n",
    "worst_model_torch = \"\"\n",
    "conf_mat_torch = None\n",
    "conf_mat_homebrew = None\n",
    "best_yhat_homebrew = None\n",
    "best_yhat_torch = None\n",
    "\n",
    "for hidden_size in (hidden_sizes):\n",
    "    for lmb in tqdm(lmb_list):\n",
    "        for eta in (eta_list):\n",
    "            np.random.seed(4155)\n",
    "            hidden1 = Layer(input_dim, hidden_size, activation=\"relu\", name=\"hidden1\")\n",
    "            hidden2 = Layer(hidden1.neurons, hidden1.neurons*2, activation=\"relu\", name=\"hidden2\")\n",
    "            hidden3 = Layer(hidden2.neurons, hidden2.neurons//2, activation=\"relu\", name=\"hidden3\")\n",
    "            output = Layer(hidden3.neurons, nbf_neurons=1, activation=\"sigmoid\" , name=\"output\")\n",
    "\n",
    "            model = NeuralNetwork(X_test_scaled, y_test.reshape(-1,1),learning_rate=eta,lmb=lmb, network_type=\"classification\")\n",
    "            model.add(hidden1)\n",
    "            model.add(hidden2)\n",
    "            model.add(hidden3)\n",
    "            model.add(output)\n",
    "\n",
    "            model.fit(X_train_scaled, y_train.reshape(-1,1), batch_size=batch_size, epochs=epochs)\n",
    "            y_hat = model.logistic_predict(X_test_scaled)\n",
    "            y_hat = y_hat.flatten()\n",
    "\n",
    "            def home_brew_accuracy(y_hat, y_true):\n",
    "                return np.sum(y_hat == y_true) / y_true.shape[0]\n",
    "\n",
    "            acc_homebrew = home_brew_accuracy(y_hat,y_test)\n",
    "            #print(f\"Accuracy: {acc}, hidden_size: {hidden_size}, lambda: {lmb}, eta: {eta}, \")\n",
    "                  \n",
    "            if acc_homebrew > best_acc_homebrew:\n",
    "                best_model_homebrew = f\"Accuracy: {acc_homebrew}\\n hidden_size: {hidden_size}, lambda: {lmb}, eta: {eta}\"\n",
    "                best_acc_homebrew = acc_homebrew\n",
    "                conf_mat_homebrew = confusion_matrix(y_test, y_hat)\n",
    "                best_yhat_homebrew = model.predict(X_test_scaled)\n",
    "                \n",
    "            if acc_homebrew < worst_acc_homebrew:\n",
    "                worst_model_homebrew = f\"Accuracy: {acc_homebrew}\\n hidden_size: {hidden_size}, lambda: {lmb}, eta: {eta}\"\n",
    "                worst_acc_homebrew = acc_homebrew\n",
    "                \n",
    "            #TORCH: \n",
    "            net_Torch = TorchNeuralNetwork(eta =eta, lmb=lmb, input_dim = X_train.shape[1], hidden_size = hidden_size)\n",
    "            net_Torch.fit(epochs, trainloader)\n",
    "\n",
    "            acc_torch = net_Torch.torch_accuracy(X_test_scaled_torch, y_test_torch)\n",
    "            \n",
    "            if acc_torch > best_acc_torch:\n",
    "                best_model_torch = f\"Accuracy: {acc_torch}\\n hidden_size: {hidden_size}, lambda: {lmb}, eta: {eta}\"\n",
    "                best_acc_torch = acc_torch\n",
    "                #torch.save(net_Torch.state_dict(),f\"{os.getcwd()}_best_torch_cls\")\n",
    "                y_hat_torch = net_Torch.forward(X_test_scaled_torch)\n",
    "                best_yhat_torch = y_hat_torch\n",
    "                prediction_val_torch = [1 if x > 0.5 else 0 for x in y_hat_torch.data.numpy()]\n",
    "                conf_mat_torch = confusion_matrix(y_test, prediction_val_torch)\n",
    "\n",
    "\n",
    "            if acc_torch < worst_acc_torch:\n",
    "                worst_model_torch = f\"Accuracy: {acc_torch}\\n hidden_size: {hidden_size}, lambda: {lmb}, eta: {eta}\"\n",
    "                worst_acc_torch = acc_torch\n",
    "                \n",
    "        \n",
    "print(f\"Best homebrew: {best_model_homebrew}\")\n",
    "print(f\"worst homebrew: {worst_model_homebrew}\")\n",
    "print(f\"Best torch: {best_model_torch}\")\n",
    "print(f\"worst torch: {worst_model_torch}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matricies: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cm_torch = sns.heatmap(conf_mat_torch,annot=True, fmt=\".0f\")\n",
    "#gridsearch.set_xticklabels(gridsearch.get_xticklabels(),rotation = 80)\n",
    "plt.title(\"Confusion Matrix Torch\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cm_homebrew = sns.heatmap(conf_mat_homebrew,annot=True, fmt=\".0f\")\n",
    "#gridsearch.set_xticklabels(gridsearch.get_xticklabels(),rotation = 80)\n",
    "plt.title(\"Confusion Matrix Homebrew\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "print(conf_mat_homebrew)\n",
    "print(conf_mat_homebrew[0][1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC curves "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "figure(figsize=(10, 10), dpi=80)\n",
    "\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, best_yhat_homebrew)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "fpr_torch, tpr_torch, threshold = metrics.roc_curve(y_test, best_yhat_torch.detach().numpy())\n",
    "roc_auc = metrics.auc(fpr_torch, tpr_torch)\n",
    "\n",
    "\n",
    "logreg_SGD = LogReg(eta = 0.0001, lmb = 0.9)\n",
    "logreg_SGD.fit(X_train_scaled,y_train,batch_size= 5, epochs=10, solver = \"SGD\")\n",
    "y_hat_SGD = logreg_SGD.forward(X_test_scaled)\n",
    "fpr_SGD, tpr_SGD, threshold = metrics.roc_curve(y_test, best_yhat_torch.detach().numpy())\n",
    "roc_auc = metrics.auc(fpr_SGD, tpr_SGD)\n",
    "plt.plot(fpr_SGD, tpr_SGD,\"o--\", label = 'LogReg(SGD)' % roc_auc)\n",
    "\n",
    "\n",
    "logreg_NRM = LogReg()\n",
    "logreg_NRM.fit(X_train_scaled,y_train,batch_size= 5, epochs=1, solver = \"NRM\")\n",
    "logreg_NRM.accuracy(X_test_scaled, y_test)\n",
    "y_hat_NRM = logreg_NRM.forward(X_test_scaled)\n",
    "\n",
    "\n",
    "fpr_NRM, tpr_NRM, threshold = metrics.roc_curve(y_test, y_hat_NRM)\n",
    "roc_auc = metrics.auc(fpr_NRM, tpr_NRM)\n",
    "plt.plot(fpr_NRM, tpr_NRM,\"o-\", label = 'LogReg NRM')\n",
    "\n",
    "plt.plot(fpr_torch, tpr_torch,\"--\", label = 'Torch' % roc_auc)\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr,\"o--\", label = 'Homebrew' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'k--')\n",
    "plt.xlim([-0.01, 1.01])\n",
    "plt.ylim([-0.01, 1.01])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_yhat_homebrew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "832cabf0b499e02e4a9db3c43ba66016f6fa525bd81e8a60b86973ed3d4bb657"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('fysstk_env': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
