{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Bias-variance trade-off and resampling techniques "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn.linear_model as lm\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.utils import resample\n",
    "from common import *\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias-variance trade-off as function of model complexity : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxdegree = 18\n",
    "for n in (20,40):\n",
    "    SEED_VALUE = np.random.seed(4155)\n",
    "    \n",
    "    x = np.sort(np.random.uniform(0, 1, n))\n",
    "    y = np.sort(np.random.uniform(0, 1, n))\n",
    "    x,y = np.meshgrid(x,y)\n",
    "    t = FrankeFunction(x,y) + noise_factor(n, factor = 0.3)\n",
    "\n",
    "    MSE_test = np.zeros(maxdegree)\n",
    "    MSE_train = np.zeros(maxdegree)\n",
    "    bias = np.zeros(maxdegree)\n",
    "    variance = np.zeros(maxdegree)\n",
    "    t_flat = t.ravel().reshape(-1, 1)\n",
    "\n",
    "    for degree in tqdm(range(1, maxdegree+1)):\n",
    "        X = create_X(x, y, n=degree)\n",
    "        X_train, X_test, t_train, t_test = prepare_data(\n",
    "            X, t_flat, SEED_VALUE, test_size=0.2, shuffle=True, scale_X=True, scale_t=False)\n",
    "\n",
    "    \n",
    "        model = OLS()\n",
    "        t_hat_train = model.fit(X_train, t_train)\n",
    "        t_predicted = model.predict(X_test)\n",
    "\n",
    "        MSE_test[degree-1] = MSE(t_test, t_predicted)\n",
    "        bias[degree-1] = np.mean(t_test - np.mean(t_predicted))**2\n",
    "        variance[degree-1] = np.var(t_predicted)\n",
    "        \n",
    "        \n",
    "    plt.semilogy(np.arange(1,maxdegree+1), MSE_test,\"m\", label='MSE test')\n",
    "    plt.semilogy(np.arange(1,maxdegree+1), bias,\"b--\", label='bias')\n",
    "    plt.semilogy(np.arange(1,maxdegree+1), variance,\"r--\", label='Variance')\n",
    "    #plt.plot(np.arange(1,maxdegree+1), variance+bias,\"o--\", label='CONTROL')\n",
    "\n",
    "\n",
    "    plt.xlabel(f\"Polynomial Degree\")\n",
    "    plt.ylabel(\"Prediction Error - MSE\")\n",
    "\n",
    "    plt.grid(True)\n",
    "    plt.legend(loc=1)\n",
    "    plt.title(f\"Bias variance trade-off, {n**2} datapoints\")\n",
    "    plt.xticks(np.arange(1,maxdegree+1))\n",
    "    #plt.savefig(f\"{REPORT_FIGURES}{EX2}model_complexity_bias_var_function_n_{n}.pdf\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias-variance trade off with Bootstrap:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_size in (0.2,0.3):\n",
    "    for n in (22,40):\n",
    "        \n",
    "        SEED_VALUE = np.random.seed(4155)\n",
    "        n_bootstraps = int((n**2)/5)\n",
    "        maxdegree = 15\n",
    "        x = np.sort(np.random.uniform(0, 1, n))\n",
    "        y = np.sort(np.random.uniform(0, 1, n))\n",
    "        x,y = np.meshgrid(x,y)\n",
    "        t = FrankeFunction(x,y) + noise_factor(n, factor=0.3)\n",
    "\n",
    "\n",
    "        polydegree = np.arange(1, maxdegree+1)\n",
    "        MSE_test, MSE_train, bias, variance = bootstrap(x, y, t, maxdegree, n_bootstraps, OLS(), SEED_VALUE, test_size = test_size)\n",
    "\n",
    "        plt.semilogy(polydegree, MSE_test,\"m\", label='MSE test')\n",
    "        plt.semilogy(polydegree, bias,\"b--\", label='bias')\n",
    "        plt.semilogy(polydegree, variance,\"r--\", label='Variance')\n",
    "        #plt.semilogy(polydegree, bias+variance,\"o--\", label='kontroll')\n",
    "        # plt.ylim(0,2)\n",
    "        #plt.plot(polydegree, bias+variance,\"g--\", label='bias+variance')\n",
    "\n",
    "        plt.xlabel(f\"Model complexity / Polynomial Degree at n={n} with {n_bootstraps} bootstraps\")\n",
    "        plt.ylabel(\"Prediction Error - MSE (Log)\")\n",
    "        plt.xticks(polydegree)\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.title(f\"{n_bootstraps} bootstraps, {n**2} datapoints. Test size: {test_size}\")\n",
    "        #plt.savefig(f\"{REPORT_FIGURES}{EX2}model_complexity_using_bootstrap_function_n_{n}_testsize_{test_size}.pdf\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
